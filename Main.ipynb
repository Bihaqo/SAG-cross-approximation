{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a gradient matrix G. We will store its low rank approximation: $G \\approx A V^\\intercal$, where $V^\\intercal V = I$.\n",
    "\n",
    "Instead of storing plain A we will store $\\hat{A}$ and $w$, where $\\hat{A} = diag(w) A$.\n",
    "\n",
    "On each iteration we will apply the maxvol to $\\hat{A}$ which is equavalent to applying it to $\\hat{G} = \\hat{A} V^\\intercal$. From maxvol we get the indices of the current batch objects. We update the corresponding rows in $\\hat{G}$ via projector splitting, reduce the weights of the currently chosen objects and proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2578107712178226"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tt\n",
    "import tt.cross\n",
    "n_objects = 200\n",
    "n_features = 100\n",
    "batch_size = 50\n",
    "weight_factor = 2.0\n",
    "# Initialize.\n",
    "a_hat = np.zeros((n_objects, batch_size))\n",
    "v = np.zeros((batch_size, n_features))\n",
    "w = np.ones(n_objects)\n",
    "direction = np.zeros(n_features)\n",
    "# Debugging.\n",
    "g_hat = np.zeros((n_objects, n_features))\n",
    "######\n",
    "\n",
    "\n",
    "# On each iteration.\n",
    "curr_objects = tt.maxvol.maxvol(a_hat)\n",
    "# Compute gradients in the chosen objects.\n",
    "new_g = np.random.rand(curr_objects.shape[0], n_features)\n",
    "weighted_new_g = new_g * (w[curr_objects] / weight_factor)[:, None]\n",
    "weighted_old_g = a_hat[curr_objects, :].dot(v)\n",
    "old_g = weighted_old_g / w[curr_objects, np.newaxis]\n",
    "direction += np.sum(new_g - old_g, axis=0)\n",
    "weighted_delta_g = -weighted_old_g + weighted_new_g\n",
    "# Update G (see A projector-splitting integrator for dynamical low-rank approximation).\n",
    "k1 = a_hat\n",
    "k1[curr_objects, :] += weighted_delta_g.dot(v.T)\n",
    "u1, s_hat_1 = np.linalg.qr(k1)\n",
    "s_hat_1 -= u1[curr_objects, :].T.dot(weighted_delta_g).dot(v.T)\n",
    "l1 = v.T.dot(s_hat_1) + weighted_delta_g.T.dot(u1[curr_objects, :])\n",
    "v1, s1 = np.linalg.qr(l1)\n",
    "a_hat = u1.dot(s1)\n",
    "v = v1.copy().T\n",
    "# Debugging.\n",
    "g_hat[curr_objects, :] = weighted_new_g\n",
    "######\n",
    "# Reduce the weights of the chosen objects.\n",
    "w[curr_objects] /= weight_factor\n",
    "\n",
    "# Debugging.\n",
    "np.linalg.norm(g_hat - a_hat.dot(v)) / np.linalg.norm(g_hat)\n",
    "\n",
    "\n",
    "\n",
    "# # Version without projector splitting (for comparison and debugging).\n",
    "# u, s, v = np.linalg.svd(g_hat)\n",
    "# u = u[:, :batch_size]\n",
    "# s = s[:batch_size]\n",
    "# v = v[:batch_size, :]\n",
    "# a_hat = u.dot(np.diag(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
